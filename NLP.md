# Paper for NLP

[![N|Solid](https://cldup.com/dTxpPi9lDf.thumb.png)](https://nodesource.com/products/nsolid)

[![Build Status](https://travis-ci.org/joemccann/dillinger.svg?branch=master)](https://travis-ci.org/joemccann/dillinger)

### General 
http://yagami12.hatenablog.com/entry/2017/12/30/175113
http://web.stanford.edu/class/cs224n/syllabus.html
 
## Word to vec
http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/
http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf
https://arxiv.org/pdf/1301.3781.pdf
https://nlp.stanford.edu/pubs/glove.pdf
http://www.aclweb.org/anthology/Q15-1016
http://www.aclweb.org/anthology/D15-1036

## Recurrent Neural Networks and Language Models
https://web.stanford.edu/~jurafsky/slp3/4.pdf
 
## Machine Translation, Seq2Seq and Attention 
https://www.aclweb.org/anthology/P02-1040.pdf
https://arxiv.org/pdf/1409.3215.pdf
https://arxiv.org/pdf/1409.0473.pdf
https://distill.pub/2016/augmented-rnns/
https://arxiv.org/pdf/1703.03906.pdf

## Advanced Attention 
https://arxiv.org/abs/1705.04304
https://arxiv.org/abs/1704.04368
https://arxiv.org/abs/1511.06909
https://arxiv.org/abs/1604.00788
https://arxiv.org/pdf/1611.01576.pdf

## Transformer Networks and CNNs
https://arxiv.org/abs/1706.03762
https://arxiv.org/pdf/1607.06450.pdf
https://arxiv.org/abs/1408.5882
https://arxiv.org/abs/1207.0580
https://arxiv.org/pdf/1404.2188.pdf

